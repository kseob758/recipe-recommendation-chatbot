# ì‚¬ì§„ ì˜† ì¬ë£Œë²„íŠ¼ -> ë§í¬ì—°ê²° (ì±—ë´‡í˜•ì‹0)
# ë¯¼ê·œë‹˜ íŒŒì¼ ì—°ê²°
# ë©”ì„¸ì§€ í”„ë¡¬í”„íŠ¸ ë³€ê²½(ê°•ì„­ë‹˜)
# user_interact í•¨ìˆ˜ ë³€ê²½(ê°•ì„­ë‹˜)


# ë°ì´í„° ë¶„ì„
import pandas as pd
import numpy as np

# ì§„í–‰ì‹œê°„ í‘œì‹œ
# import swifter
from tqdm.notebook import tqdm

## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st 

# íŒŒì´í† ì¹˜
import torch

# ë¬¸ì¥ ì„ë² ë”©, transformer ìœ í‹¸ë¦¬í‹°
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer, util
from sentence_transformers import SentenceTransformer, models
# Owl-ViTë¥¼ ìœ„í•œ ì „ì²˜ë¦¬, ê°ì²´ ê°ì§€
from transformers import OwlViTProcessor, OwlViTForObjectDetection
# íŒŒì´í”„ë¼ì¸ êµ¬ì„±
from transformers import pipeline
# GPT-2 í† í¬ë‚˜ì´ì €
from transformers import GPT2TokenizerFast

# ì´ë¯¸ì§€ ì²˜ë¦¬
from PIL import Image
# ì‚¬ì´í‚· ëŸ°
import sklearn.datasets as datasets
import sklearn.manifold as manifold

# ë°ì´í„° ìˆ˜ì§‘
import requests
from bs4 import BeautifulSoup

# ê°ì²´ ë³µì‚¬
import copy
# JSON í˜•ì‹ ë°ì´í„° ì²˜ë¦¬
import json
# íƒ€ì… íŒíŠ¸
from typing import List, Tuple, Dict

# ë°ì´í„°ë² ì´ìŠ¤ í™œìš©
import sqlite3 
import pickle

# OpenAI API í™œìš©
import openai 
import os # ìš´ì˜ì²´ì œ
import sys # íŒŒì´ì¬ ë³€ìˆ˜, í•¨ìˆ˜ ì—‘ì„¸ìŠ¤ 
# from dotenv import load_dotenv # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ(API Key ë³´ì•ˆ)
import io

# ìŠ¤íŠ¸ë¦¼ë¦¿ êµ¬í˜„
import streamlit
from streamlit_chat import message
import global_list

from dotenv import load_dotenv # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ(API Key ë³´ì•ˆ)



## íŒŒì¼ ë° API ê°€ì ¸ì˜¤ê¸°
# app.py íŒŒì¼ì´ ìœ„ì¹˜í•œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
APP_DIR = os.path.dirname(os.path.abspath(__file__))
# app.pyì—ì„œ ë§Œë“  ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜¤ê¸°
LAST_DF_PATH = os.path.join(APP_DIR, '../last_df.pkl')
df = pd.read_pickle(LAST_DF_PATH)
df = df.reset_index(drop=True)

load_dotenv()    
openai.api_key = os.getenv('OPENAI_API_KEY')
# openai.api_key = ''

# ì‹¤í–‰ os í™•ì¸
cur_os = sys.platform

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ í‚¤
CHAT_HISTORY_KEY = "chat_history"

# íŒŒìƒ ë³€ìˆ˜
# - feature1 = 'ì¬ë£Œ'
# - feature2 = 'ì¬ë£Œ' + 'ìš”ë¦¬'
# - feature3 = 'ì¬ë£Œ' + 'ìš”ë¦¬' + 'ì¢…ë¥˜'
# - feature4 = 'ì¬ë£Œ' + 'ìš”ë¦¬' + 'ì¢…ë¥˜' + 'ë‚œì´ë„'
# - feature5 = 'ì¬ë£Œ' + 'ìš”ë¦¬' + 'ì¢…ë¥˜' + 'ë‚œì´ë„' + 'ìš”ë¦¬ë°©ë²•'
# - feature6 = 'ì¬ë£Œ' + 'ìš”ë¦¬' + 'ì„¤ëª…' + 'ì¢…ë¥˜' + 'ë‚œì´ë„' + 'ìš”ë¦¬ë°©ë²•'



## ëª¨ë¸ ì„ ì–¸
model_name = 'jhgan/ko-sroberta-multitask'
model = SentenceTransformer(model_name)



## ìƒìœ„ 5ê°œ í•­ëª© ì¶œë ¥(ë§í¬ë¡œ ì¤‘ë³µì œê±°-ë¯¼ê·œë‹˜)
def get_query_sim_top_k(query, model, df):
    "ì¿¼ë¦¬ì™€ ë°ì´í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³  ìœ ì‚¬í•œ ìˆœìœ„ 5ê°œ ë°˜í™˜"
    query_encode = model.encode(query)
    cos_scores = util.pytorch_cos_sim(query_encode, df['ko-sroberta-multitask-feature'])[0]
    top_results = torch.topk(cos_scores, k=1)
    return top_results

# query = 'ê³ ê¸° ìª½íŒŒ'
# top_result = get_query_sim_top_k(query, model, df)


# df.iloc[top_result[1].numpy(), :][['ìš”ë¦¬', 'ì¢…ë¥˜', 'ì¬ë£Œ']]



## ë©”ì„¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
# intentì—ì„œ ì˜ë„ íŒŒì•…í•˜ê³  recom í˜¹ì€ desc ë¡œ íŒë‹¨ë˜ëŠ” ê²ƒ.
msg_prompt = {
    'recom' : {
                'system' : "You are a helpful assistant who recommend movie based on user question.", 
                'user' : "Write 1 sentence of a very simple greeting that starts with 'ì¶”ì²œë“œë¦¬ê² ìŠµë‹ˆë‹¤!' to recommend food items to users. and don't say any food name, say in korean", 
              },
    'desc' : {
                'system' : "You are a assistant who very simply answers.", 
                'user' : "Please write a simple greeting starting with 'ìš”ë¦¬ì— ëŒ€í•´ ì„¤ëª…í• ê²Œìš”' to explain the recipes to the user.", 
              },
    'how' : {
                'system' : "You are a helpful assistant who kindly answers.", 
                'user' : "Please write a simple greeting starting with 'ë°©ë²•ì„ ë§ì”€ë“œë¦´ê²Œìš”' to explain the recipes to the user.", 
              },
    'intent' : {
                'system' : "You are a helpful assistant who understands the intent of the user's query. and You answer in a short answer",
                'user' : "Which category does the sentence below belong to: 'recommendation', 'description', how to cook'? pick one category. \n context:"
                }
}


## OpenAI APIì™€ GPT-3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ msgì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
# ì´ì „ ëŒ€í™”ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬ ëŒ€í™” ìƒì„±.
def get_chatgpt_msg(msg):
    completion = openai.ChatCompletion.create(
                    model='gpt-3.5-turbo',
                    messages=msg
                    )
    return completion['choices'][0]['message']['content']



## intentì™€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ prompt ìƒì„±
# ì ì ˆí•œ ì´ˆê¸° ë©”ì„¸ì§€ ìƒì„±, ì‚¬ìš©ìì™€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”êµ¬ì„± ê°€ëŠ¥.
def set_prompt(intent, query, msg_prompt_init, model):
    '''prompt í˜•íƒœë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜'''
    m = dict()
    # ì¶”ì²œì¼ ê²½ìš°
    if 'recom' in intent:
        msg = msg_prompt_init['recom']  # ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ê°€ì ¸ì˜´
    # ì„¤ëª…ì¼ ê²½ìš°
    elif 'desc' in intent:
        msg = msg_prompt_init['desc']  # ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ê°€ì ¸ì˜´
    # ìš”ë¦¬ë°©ë²•ì¼ ê²½ìš°
    elif 'how' in intent:
        msg = msg_prompt_init['how']  # ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ê°€ì ¸ì˜´
    # intent íŒŒì•…
    else:
        msg = msg_prompt_init['intent']
        msg['user'] += f' {query} \n A:'
    for k, v in msg.items():
        m['role'], m['content'] = k, v
    return [m]



## ì…ë ¥ëœ í…ìŠ¤íŠ¸ì— ëŒ€í•´ gpt ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±.
# í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³ , ìƒì„±ëœ ì‘ë‹µì„ ë””ì½”ë”© í•˜ì—¬ ë°˜í™˜.
# ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•´ì„œë§Œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±(ì´ì „ ëŒ€í™” ê³ ë ¤ x)
def generate_answer(model, tokenizer, input_text, max_len=50):
    input_ids = tokenizer.encode(input_text, return_tensors='pt')
    # generate text until the specified length
    output = model.generate(input_ids=input_ids, max_length=max_len, do_sample=True, top_p=0.92, top_k=50)
    # decode the generated text
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    return response

import base64
import webbrowser

def user_interact(query, model, msg_prompt_init):
    global global_list
    # 1. ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…
    user_intent = set_prompt('intent', query, msg_prompt_init, None)
    user_intent = get_chatgpt_msg(user_intent).lower()
    print("user_intent : ", user_intent)
    
    # 2. ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— ë”°ë¼ prompt ìƒì„±    
    intent_data = set_prompt(user_intent, query, msg_prompt_init, model)
    intent_data_msg = get_chatgpt_msg(intent_data).replace("\n", "").strip()
    print("intent_data_msg : ", intent_data_msg)
    
    # 3-1. ì¶”ì²œì´ë©´
    if ('recom' in user_intent):
        
        global_list.user_msg_history = []
        recom_msg = str()
        
        top_result = get_query_sim_top_k(query, model, df)
        #print("top_result : ", top_result)
        # ê²€ìƒ‰ì´ë©´, ìê¸° ìì‹ ì˜ ì»¨í…ì¸ ëŠ” ì œì™¸
        top_index = top_result[1].numpy() if 'recom' in user_intent else top_result[1].numpy()[1:]
        #print("top_index : ", top_index)
        # ìš”ë¦¬, ì¢…ë¥˜, ì¬ë£Œë¥¼ ê°€ì ¸ì™€ì„œ ì¶œë ¥
        r_set_d = df.iloc[top_index, :][['ìš”ë¦¬', 'ì¢…ë¥˜', 'ì¬ë£Œ', 'ì‚¬ì§„', 'ìš”ë¦¬ë°©ë²•']]
        r_set_d = json.loads(r_set_d.to_json(orient="records"))
        for r in r_set_d:
            for _, v in r.items():
                recom_msg += f"{v} \n"
                # 'ì‚¬ì§„' ì»¬ëŸ¼ì—ì„œ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
                img_url = r['ì‚¬ì§„']
                response = requests.get(img_url)
                image_bytes = io.BytesIO(response.content)
                image = Image.open(image_bytes)
                img_md = f"<img src='data:image/png;base64,{base64.b64encode(image_bytes.getvalue()).decode()}' style='padding-left: 70px; width:550px;'/>"

                # ì¬ë£Œ êµ¬ë§¤ë§í¬ ìƒì„±
                r_ingredients = r['ì¬ë£Œ'].split()
                button_html = ''
                for ing in r_ingredients:
                    gs_url = f"https://m.gsfresh.com/shop/search/searchSect.gs?tq={ing}&mseq=S-11209-0301&keyword={ing}"
                    button_html += f"""<span style="white-space: nowrap;"><a href="{gs_url}" target="_blank" style="text-decoration: none; color: white; background-color: #008A7B; padding: 6px 12px; border-radius: 5px; margin-right: 5px; margin-bottom: 5px; margin-top: 5px;">{ing}</a></span>"""
                
                # ìš”ë¦¬ë°©ë²•
                def recipe():
                    recipe_str = ''
                    for i, step in enumerate(recipe_steps):
                        step = step.strip()  
                        if step:  
                            recipe_str += f"{i+1}. {step}\n\n"
                    return recipe_str
                recipe_steps = r['ìš”ë¦¬ë°©ë²•'].replace('[', '').replace(']', '').replace("\\xa0", " ").replace("\\r\\n", ' ').split("', ")
                recipe_steps = [step.split("\\n") for step in recipe_steps]
                recipe_steps = [step for sublist in recipe_steps for step in sublist]
                recipe_steps = [step.strip() for step in recipe_steps]
                recipe_steps = [step.replace("'", "") for step in recipe_steps]
                # recipe_str = "\n\n".join(recipe_steps)
                            
            recom_msg = f"ì¶”ì²œë©”ë‰´ \" {r['ìš”ë¦¬']} \" ({r['ì¢…ë¥˜']})"
            recipe_msg = ""  # recipe_msg ë³€ìˆ˜ ì´ˆê¸°í™”
            recipe_msg += f"\"{r['ìš”ë¦¬']}\" ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”. \n\n "
            recipe_msg += recipe()

        global_list.user_msg_history.append({'role' : 'assistant', 'content' : [query, f"{intent_data_msg} {str(recom_msg)}"]})
        # print(f"\nrecom data : \n{str(recom_msg)}")
        return recom_msg, img_md, f"{intent_data_msg}", button_html, recipe_msg, img_url
    
    # 3-2. ì„¤ëª…ì´ë©´
    elif 'desc' in user_intent:
        # ì²˜ìŒ ë©”ì„¸ì§€ ì»¨í…ì¸ ë¥¼ ê°€ì ¸ì˜´
        top_result = get_query_sim_top_k(global_list.user_msg_history[0]['content'][0], model, df)
        # ì„¤ëª… ì»¬ëŸ¼ì˜ ê°’ì„ ê°€ì ¸ì™€ ì¶œë ¥
        r_set_n = df.loc[top_result[1].numpy(), 'ìš”ë¦¬']
        r_set_d = df.iloc[top_result[1].numpy(), :]['ì„¤ëª…']
        r_set_d = json.loads(r_set_d.to_json(orient="records"))[0]
        # r_set_d_value = r_set_d.iloc[0].values[0] ì›ë˜ ê²ƒ
        # r_set_d = r_set_d.iloc[-1].values[0]
        global_list.user_msg_history.append({'role' : 'assistant', 'content' : r_set_d})
        return f' "{r_set_n.iloc[-1]}" ì†Œê°œë¥¼ í•´ë“œë¦´ê²Œìš”! \n\n {r_set_d}'

    
    # 3-3. ìš”ë¦¬ë°©ë²•ì´ë©´
    elif 'how' in user_intent:
        # ì²˜ìŒ ë©”ì„¸ì§€ ì»¨í…ì¸ ë¥¼ ê°€ì ¸ì˜´
        top_result = get_query_sim_top_k(global_list.user_msg_history[0]['content'][0], model, df)
        # ìš”ë¦¬ë°©ë²• ì»¬ëŸ¼ì˜ ê°’ì„ ê°€ì ¸ì™€ ì¶œë ¥
        r_set_d = df.iloc[top_result[1].numpy(), :]['ìš”ë¦¬ë°©ë²•']
        r_set_n = df.iloc[top_result[1].numpy(), :]['ìš”ë¦¬'].values[0]
        
        # ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„í• í•˜ê³  ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        r_set_d_list = []
        for s in r_set_d:
            s_list = s.split("', ")
            # ì‘ì€ë”°ì˜´í‘œì™€ ì½¤ë§ˆë¥¼ ì œê±°í•˜ê³  ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            for i in range(len(s_list)):
                s_list[i] = s_list[i].replace("'", "").replace(",", "").replace('[','').replace(']','').replace('\\xa0', ' ').replace('\\r\\n', '')
            r_set_d_list.extend(s_list)
            
        # ìˆœë²ˆê³¼ í•¨ê»˜ ì¶œë ¥
        re_num = ""
        for i, s in enumerate(r_set_d_list, 1):
            re_num += f"{i}. {s} \n"
        global_list.user_msg_history.append({'role' : 'assistant', 'content' : r_set_d_list})

        return f'"{r_set_n}" ìš”ë¦¬ë°©ë²•ì„ ì•Œë ¤ë“œë¦´ê²Œìš”! \n\n {re_num}'
            




st.set_page_config(page_title="Chat!ê°•ë¡", page_icon=":cook:", layout="wide")

if __name__ == "__main__":
    # ë©”ì¸ êµ¬ì„±í•˜ê¸°
    st.markdown("<span style='color:lightgray; font-style:italic; font-size:12px;'>FINAL PROJECT(3ì¡°) 'ì¡°ì´ë¦„ì€ ìµœê°•ë¡ìœ¼ë¡œ í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ì œ ë°”ì§ˆì„ ê³ë“¤ì¸' </span>", 
                unsafe_allow_html=True)
        # ë°°ë„ˆ ì´ë¯¸ì§€ ë„£ê¸°
    curr_dir = os.getcwd()
    img_path = os.path.join(curr_dir, "chatê°•ë¡2-1.jpg")
    image = Image.open(img_path)
    st.image(image)
    img_path = os.path.join(curr_dir, "chatê°•ë¡2-2.jpg")
    image2 = Image.open(img_path)
    st.image(image2)

    # st.markdown(':loudspeaker: <span style="color: #FF0033; font-weight: bold; font-size: 12px; font-style: italic;"> "ê³ êµ¬ë§ˆ ë§›íƒ• ë ˆí”¼ì‹œ ì¶”ì²œí•´ì¤˜." í˜¹ì€ "ê¶ì¤‘ë–¡ë³¶ì´ ì„¤ëª…í•´ì¤˜." ë¼ê³  ì…ë ¥í•´ë³´ì„¸ìš”!</span>', unsafe_allow_html=True)
    st.write('\n')
    st.write('\n\n')
   

    chat_history = st.session_state.get(CHAT_HISTORY_KEY, [])

    
    
    # ì±—ë´‡ ìƒì„±í•˜ê¸°
    if not hasattr(st.session_state, 'generated'):
        st.session_state.generated = []

    if not hasattr(st.session_state, 'past'):
        st.session_state.past = []


    


    # ì¿¼ë¦¬ ë³€í˜•í•˜ê¸°
    query = None
    with st.form(key='my_form'):
        query = st.text_input('ì…ë ¥ì°½ â†“')
        submitted = st.form_submit_button('ì§ˆë¬¸í•˜ê¸°')




     # ìˆ˜í–‰ë¬¸ ë§Œë“¤ê¸°
    if submitted and query:
        output = user_interact(query, model, msg_prompt)
        chat_history.append(query)
        st.session_state.past.append(query)
        st.session_state.past.append(output)
        if isinstance(output, tuple): # ë°˜í™˜ê°’ì´ íŠœí”Œì¸ ê²½ìš°
            message(output[2],key=str(len(st.session_state.past)) + '2_assistant')
            st.markdown(f"<div style='padding-left: 70px;'> <h5> ğŸ³ {output[0]} </h5> </div>", unsafe_allow_html=True)
            st.markdown(output[1], unsafe_allow_html=True)
            # message(output[3], is_user=False, key=str(len(st.session_state.past)) + '_assistant')
            message(output[4],key=str(len(st.session_state.past)) + '4_assistant')
            st.markdown(f"<p style='padding-left: 70px; padding-right: 120px; font-size:16px; font-weight:bold; font-style:italic;'> (ì¬ë£Œë¥¼ ëˆ„ë¥´ì‹œë©´ êµ¬ë§¤í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.) <br> <span class='no-style'>{output[3]}</span> </p>", unsafe_allow_html=True)
            chat_history.append(output)
        else:
            message(output, is_user=False, key=str(len(st.session_state.past)) + '_assistant')
            chat_history.append(output)
        message(query, is_user=True, key=str(len(st.session_state.past)) + '_user')

        st.session_state[CHAT_HISTORY_KEY] = chat_history


        
    # # ì¶œë ¥í•˜ê¸°
    # if len(chat_history) > 2:
    #     for i in range(len(chat_history)-3,-1,-1):
    #         if i % 2 == 0:
    #             message(chat_history[i], is_user=True, key=str(i)+ '_user+pass') 
    #         else : 
    #             message(chat_history[i], is_user=False, key=str(i)+ '_assistant+pass') 
    if len(chat_history) > 2:
        for i in range(len(chat_history)-3, -1, -1):
            if i % 2 == 0:
                message(chat_history[i], is_user=True, key=str(i)+ '_user+pass') 
            else :
                if isinstance(chat_history[i], tuple) :
                    message(chat_history[i][2], is_user=False, key=str(i) + '2_assistant+pass')
                    st.markdown(f"<div style='padding-left: 70px;'> <h5> ğŸ³ {chat_history[i][0]} </h5> </div>", unsafe_allow_html=True)
                    st.markdown(chat_history[i][1], unsafe_allow_html=True)
                    message(chat_history[i][4], is_user=False, key=str(i) + '4_assistant+pass')
                    st.markdown(f"<p style='padding-left: 70px; padding-right: 120px; font-size:16px; font-weight:bold; font-style:italic;'> (ì¬ë£Œë¥¼ ëˆ„ë¥´ì‹œë©´ êµ¬ë§¤í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.) <br> <span class='no-style'>{chat_history[i][3]}</span> </p>", unsafe_allow_html=True)
                else:
                    message(chat_history[i], is_user=False, key=str(i)+ '_assistant+pass')